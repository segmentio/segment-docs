---
title: Analytics for Node.js
redirect_from: '/connections/sources/catalog/libraries/server/node-js/'
repo: analytics-next
strat: node-js
support_type: flagship
---

Segment's Analytics Node.js library lets you record analytics data from your node code. The requests hit Segment's servers, and then Segment routes your data to any destinations you have enabled.

The [Segment Analytics Node.js Next library is open-source](https://github.com/segmentio/analytics-next/tree/master/packages/node){:target="_blank"} on GitHub.

All of Segment's server-side libraries are built for high-performance, so you can use them in your web server controller code. This library uses an internal queue to make Identify and Track calls non-blocking and fast. It also batches messages and flushes asynchronously to Segment's servers.

## Getting started

> warning ""
> Make sure you're using a version of Node that's 18 or higher. 

1. Run the relevant command to add Segment's Node library module to your `package.json`.

    ```bash
    # npm
    npm install @segment/analytics-node
    # yarn
    yarn add @segment/analytics-node
    # pnpm
    pnpm add @segment/analytics-node
    ```

2. Initialize the `Analytics` constructor the module exposes with your Segment source **Write Key**:

    ```javascript
    import { Analytics } from '@segment/analytics-node'
    // or, if you use require:
    const { Analytics } = require('@segment/analytics-node')

    // instantiation
    const analytics = new Analytics({ writeKey: '<YOUR_WRITE_KEY>' })
    ```

  Replace `YOUR_WRITE_KEY` with your actual **Write Key** which you can find in Segment by navigating to: **Connections > Sources** and selecting your source and going to the **Settings** tab.

  This creates an instance of `Analytics` that you can use to send data to Segment for your project. The default initialization settings are production-ready and queue 20 messages before sending any requests. 


## Basic tracking methods
The basic tracking methods below serve as the building blocks of your Segment tracking. They include [Identify](#identify), [Track](#track), [Page](#page), [Group](#group), and [Alias](#alias).

These methods correspond with those used in the [Segment Spec](/docs/connections/spec/). The documentation on this page explains how to use these methods in Analytics Node.js Next.


### Identify

> info ""
> For any of the different methods described on this page, you can replace the properties and traits in the code samples with variables that represent the data collected.

Identify lets you tie a user to their actions and record traits about them.  It includes a unique User ID and/or anonymous ID, and any optional traits you know about them.

You should call Identify once when the user's account is first created, and then again any time their traits change.

Example of an anonymous Identify call:

```javascript
analytics.identify({
  anonymousId: '48d213bb-95c3-4f8d-af97-86b2b404dcfe',
  traits: {
    friends: 42
  }
});
```

This call identifies the user and records their unique anonymous ID, and labels them with the `friends` trait.

Example of an Identify call for an identified user:

```javascript
analytics.identify({
  userId: '019mr8mf4r',
  traits: {
    name: 'Michael Bolton',
    email: 'mbolton@example.com',
    plan: 'Enterprise',
    friends: 42
  }
});
```
The call above identifies Michael by his unique User ID (the one you know him by in your database), and labels him with the `name`, `email`, `plan`, and `friends` traits.

An Identify call has the following fields:

Field | Details
----- | -------
`userId` _String, optional_ | The ID for this user in your database. _Note: at least one of `userId` or `anonymousId` must be included in any Identify call._
`anonymousId` _String, optional_ | An ID associated with the user when you don't know who they are (for example, [the anonymousId generated by `analytics.js`](/docs/connections/sources/catalog/libraries/website/javascript/#anonymous-id)). _Note: You must include at least one of `userId` or `anonymousId` in all Identify calls._
`traits` _Object, optional_ | A dictionary of [traits](/docs/connections/spec/identify#traits) you know about the user. Things like: `email`, `name`, or `friends`.
`timestamp` _Date, optional_ | A JavaScript date object representing when the identify took place. If the identify just happened, leave it out as Segment uses the server's time. If you're importing data from the past make sure to send a `timestamp`.
`context` _Object, optional_ | A dictionary of extra [context](/docs/connections/spec/common/#context) to attach to the call. _Note: `context` differs from `traits` because it is not attributes of the user itself._

Find details on the **Identify method payload** in Segment's [Spec](/docs/connections/spec/identify/).

### Track

Track lets you record the actions your users perform. Every action triggers what Segment calls an "event", which can also have associated properties.

You'll want to track events that are indicators of success for your site, like **Signed Up**, **Item Purchased**, or **Article Bookmarked**.

To get started, we recommend tracking just a few important events. You can always add more later.

Example anonymous Track call:

```javascript
analytics.track({
  anonymousId: '48d213bb-95c3-4f8d-af97-86b2b404dcfe',
  event: 'Item Purchased',
  properties: {
    revenue: 39.95,
    shippingMethod: '2-day'
  }
});
```

Example identified Track call:

```javascript
analytics.track({
  userId: '019mr8mf4r',
  event: 'Item Purchased',
  properties: {
    revenue: 39.95,
    shippingMethod: '2-day'
  }
});
```

This example Track call tells you that your user just triggered the **Item Purchased** event with a revenue of $39.95 and chose your hypothetical '2-day' shipping.

Track event properties can be anything you want to record. In this case, revenue and shipping method.

The Track call has the following fields:

Field | Details 
----- | --------
`userId` _String, optional_ | The ID for this user in your database. _Note: at least one of `userId` or `anonymousId` must be included in any Track call.
`anonymousId` _String, optional_ | An ID associated with the user when you don't know who they are (for example, [the anonymousId generated by `analytics.js`](/docs/connections/sources/catalog/libraries/website/javascript/#anonymous-id)). _Note: You must include at least one of `userId` or `anonymousId` in all Track calls._
`event` _String_ | The name of the event you're tracking. We recommend human-readable names like `Song Played` or `Status Updated`.
`properties` _Object, optional_ | A dictionary of properties for the event. If the event was `Product Added`, it might have properties like `price` or `product`.
`timestamp` _Date, optional_ | A JavaScript date object representing when the track took place. If the track just happened, leave it out and we'll use the server's time. If you're importing data from the past make sure you to send a `timestamp`.
`context` _Object, optional_ | A dictionary of extra [context](/docs/connections/spec/common/#context) to attach to the call. _Note: `context` differs from `traits` because it is not attributes of the user itself._

Find details on **best practices in event naming** as well as the **Track method payload** in the [Segment Spec](/docs/connections/spec/track/).

### Page

The [Page](/docs/connections/spec/page/) method lets you record page views on your website, along with optional extra information about the page being viewed.

If you're using Segment's client-side set up in combination with the Node.js library, Page calls are **already tracked for you** by default. However, if you want to record your own page views manually and aren't using the client-side library, read on.

Example Page call:

```js
analytics.page({
  userId: '019mr8mf4r',
  category: 'Docs',
  name: 'Node.js Library',
  properties: {
    url: 'https://segment.com/docs/connections/sources/catalog/librariesnode',
    path: '/docs/connections/sources/catalog/librariesnode/',
    title: 'Node.js Library - Segment',
    referrer: 'https://github.com/segmentio/analytics-node'
  }
});
```

A Page call has the following fields:

Field | Details 
----- | --------
`userId` _String, optional_ | The ID for this user in your database. _Note: at least one of `userId` or `anonymousId` must be included in any Page call.
`anonymousId` _String, optional_ | An ID associated with the user when you don't know who they are (for example, [the anonymousId generated by `analytics.js`](/docs/connections/sources/catalog/libraries/website/javascript/#anonymous-id)). _Note: at least one of `userId` or `anonymousId` must be included in any Page call._
`category` _String, optional_ | The category of the page. Useful for industries, like ecommerce, where many pages often live under a larger category.
`name` _String, optional_ | The name of the page, for example **Signup** or **Home**.
`properties` _Object, optional_ | A dictionary of properties of the page. A few properties specially recognized and automatically translated: `url`, `title`, `referrer`, and `path`, but you can add your own too.
`timestamp` _Date, optional_ | A JavaScript date object representing when the Page took place. If the Page just happened, leave it out and Segment will use the server's time. If you're importing data from the past make sure you to send a `timestamp`.
`context` _Object, optional_ | A dictionary of extra [context](docs/connections/spec/common/#context) to attach to the call. _Note: `context` differs from `traits` because it is not attributes of the user itself._

Find details on the **Page payload** in the [Segment Spec](/docs/connections/spec/page/).

### Group

Group lets you associate an [identified user](/docs/connections/sources/catalog/libraries/server/node/#identify) with a group. A group could be a company, organization, account, project or team. It also lets you record custom traits about the group, like industry or number of employees.

This is useful for tools like [Intercom](/docs/connections/destinations/catalog/intercom/), [Preact](/docs/connections/destinations/catalog/preact/), and [Totango](/docs/connections/destinations/catalog/totango/), as it ties the user to a **group** of other users.

Example Group call:

```javascript
analytics.group({
  userId: '019mr8mf4r',
  groupId: '56',
  traits: {
    name: 'Initech',
    description: 'Accounting Software'
  }
});
```

The Group call has the following fields:

Field | Details
----- | --------
`userId` _String, optional_ | The ID for this user in your database. _Note: at least one of `userId` or `anonymousId` must be included in any Group call.
`anonymousId` _String, optional_ | An ID associated with the user when you don't know who they are. For example, the [anonymousId generated by `analytics.js`](/docs/connections/sources/catalog/libraries/website/javascript/#anonymous-id). _Note: at least one of `userId` or `anonymousId` must be included in any Group call._
`groupId` _string | The ID of the group.
`traits` _dict, optional_ | A dict of traits you know about the group. For a company, they might be things like `name`, `address`, or `phone`. [Learn more about traits](/docs/connections/spec/group/#traits).
`context` _dict, optional_ | A dict containing any context about the request. To see the full reference of supported keys, check them out in the [context reference](/docs/connections/spec/common/#context).
`timestamp` _datetime, optional_ | A `datetime` object representing when the Group call took place. If the Group call just happened, leave it out and Segment will use the server's time. If you're importing data from the past make sure you send `timestamp`.
`integrations` _dict, optional_ | A dictionary of destinations to enable or disable.

Find more details about Group, including the **Group payload**, in the [Segment Spec](/docs/connections/spec/group/).

### Alias

The Alias call allows you to associate one identity with another. This is an advanced method and should not be widely used, but is required to manage user identities in _some_  destinations. Other destinations do not support the Alias call.

In [Mixpanel](/docs/connections/destinations/catalog/mixpanel/#alias) it's used to associate an anonymous user with an identified user once they sign up. For [Kissmetrics](/docs/connections/destinations/catalog/kissmetrics/#alias), if your user switches IDs, you can use the Alias call to rename the `userId`.

Example Alias call:

```javascript
analytics.alias({
  previousId: 'old_id',
  userId: 'new_id'
});
```

The Alias call has the following fields:

Field | Details 
----- | --------
`userId` _String_ | The ID for this user in your database.
`previousId` _String_ | The previous ID to alias from.

Here's a full example of how Segment might use the Alias call:

```javascript
// the anonymous user does actions ...
analytics.track({ userId: 'anonymous_user', event: 'Anonymous Event' })
// the anonymous user signs up and is aliased
analytics.alias({ previousId: 'anonymous_user', userId: 'identified@example.com' })
// the identified user is identified
analytics.identify({ userId: 'identified@example.com', traits: { plan: 'Free' } })
// the identified user does actions ...
analytics.track({ userId: 'identified@example.com', event: 'Identified Action' })
```

For more details about Alias, including the **Alias call payload**, check out the [Segment Spec](/docs/connections/spec/alias/).


## Configuration

The second argument to the `Analytics` constructor is an optional list of settings to configure the module.

```javascript
const analytics = new Analytics({
    writeKey: '<MY_WRITE_KEY>',
    host: 'https://api.segment.io',
    path: '/v1/batch',
    maxRetries: 3,
    flushAt: 15,
    flushInterval: 10000,
    // ... and more!
  })
```

Setting | Details
------- | --------
`writeKey` _string_ | The key that corresponds to your Segment.io project
`host` _string_ | The base URL of the API. The default is: "https://api.segment.io"
`path` _string_ | The API path route. The default is: "/v1/batch"
`maxRetries` _number_ | The number of times to retry flushing a batch. The default is: `3`
`flushAt` _number_ | The number of messages to enqueue before flushing. The default is: `15`
`flushInterval` _number_ | The number of milliseconds to wait before flushing the queue automatically. The default is: `10000`
`httpRequestTimeout` _number_ | The maximum number of milliseconds to wait for an http request. The default is: `10000`
`disable` _boolean_ | Disable the analytics library for testing. The default is: `false`
`httpClient` _HTTPClient or HTTPClientFn_ | A custom HTTP Client implementation to support alternate libraries or proxies. Defaults to global fetch or node-fetch for older versions of node. See the [Overriding the default HTTP Client](#override-the-default-http-client) section for more details.

See the complete `AnalyticsSettings` interface [in the analytics-next repository](https://github.com/segmentio/analytics-next/blob/master/packages/node/src/app/settings.ts){:target="_blank"}.

## Usage in serverless environments and non-node runtimes
Segment supports a variety of runtimes, including, but not limited to:
- AWS Lambda
- Cloudflare Workers
- Vercel Edge Functions
- Web Workers / Browser (no device mode destination support)

### Usage in AWS Lambda
- [AWS lambda execution environment](https://docs.aws.amazon.com/lambda/latest/dg/lambda-runtime-environment.html){:target="_blank"} is challenging for typically non-response-blocking async activities like tracking or logging, since the runtime terminates or freezes after a response is emitted.

Here is an example of using analytics.js within a handler:
```ts
const { Analytics } = require('@segment/analytics-node');

 // Preferable to create a new analytics instance per-invocation. Otherwise, we may get a warning about overlapping flush calls. Also, custom plugins have the potential to be stateful, so we prevent those kind of race conditions.
const createAnalytics = () => new Analytics({
      writeKey: '<MY_WRITE_KEY>',
    }).on('error', console.error);

module.exports.handler = async (event) => {
  const analytics = createAnalytics()

  analytics.identify({ ... })
  analytics.track({ ... })

  // ensure analytics events get sent before program exits
  await analytics.flush()

  return {
    statusCode: 200,
  };
  ....
};
```

### Usage in Vercel Edge Functions

```ts
import { Analytics } from '@segment/analytics-node';
import { NextRequest, NextResponse } from 'next/server';

const createAnalytics = () => new Analytics({
  writeKey: '<MY_WRITE_KEY>',
}).on('error', console.error)

export const config = {
  runtime: 'edge',
};

export default async (req: NextRequest) => {
  const analytics = createAnalytics()

  analytics.identify({ ... })
  analytics.track({ ... })

  // ensure analytics events get sent before program exits
  await analytics.flush()

  return NextResponse.json({ ... })
};
```

### Usage in Cloudflare Workers

```ts
import { Analytics, Context } from '@segment/analytics-node';


const createAnalytics = () => new Analytics({
  writeKey: '<MY_WRITE_KEY>',
}).on('error', console.error);

export default {
  async fetch(
    request: Request,
    env: Env,
    ctx: ExecutionContext
  ): Promise<Response> {
    const analytics = createAnalytics()

    analytics.identify({ ... })
    analytics.track({ ... })

    // ensure analytics events get sent before program exits
    await analytics.flush()

    return new Response(...)
  },
};

```

## Graceful shutdown
Avoid losing events after shutting down your console. Call `.flush({ close: true })` to stop collecting new events and flush all existing events. If a callback on an event call is included, this also waits for all callbacks to be called, and any of their subsequent promises to be resolved.

```javascript
await analytics.flush({ close: true })
// or
await analytics.flush({ close: true, timeout: 5000 }) // force resolve after 5000ms
```

Here's an example of how to use graceful shutdown:
```javascript
const app = express()
const server = app.listen(3000)

const onExit = async () => {
  await analytics.flush({ close: true })
  server.close(() => {
    console.log("Gracefully closing server...")
    process.exit()
  })
}
['SIGINT', 'SIGTERM'].forEach((code) => process.on(code, onExit))
```

### Collect unflushed events 
If you need to preserve all of your events in the instance of a forced timeout, even ones that came in after analytics.flush({ close: true }) was called, you can still collect those events by using:

```javascript
const unflushedEvents = []

analytics.on('call_after_close', (event) => unflushedEvents.push(events))
await analytics.flush({ close: true })

console.log(unflushedEvents) // all events that came in after flush was called
```

## Regional configuration
For Business plans with access to [Regional Segment](/docs/guides/regional-segment), you can use the `host` configuration parameter to send data to the desired region:
1. Oregon (Default) — `api.segment.io/v1`
2. Dublin — `events.eu1.segmentapis.com`

An example of setting the host to the EU endpoint using the Node library is:
```javascript
const analytics = new Analytics({
  ...
  host: "https://events.eu1.segmentapis.com"
});
```

## Error handling

To keep track of errors, subscribe and log all event delivery errors by running:

```javascript
const analytics = new Analytics({ writeKey: '<MY_WRITE_KEY>' })

analytics.on('error', (err) => console.error(err))
```


### Event emitter interface
The event emitter interface allows you to pass a callback which will be invoked whenever a specific emitter event occurs in your app, such as when a certain method call is made.

For example:

```javascript
analytics.on('track', (ctx) => console.log(ctx))
analytics.on('error', (err) => console.error(err))


// when triggered, emits an event of the shape:
analytics.on('http_request', (event) => console.log(event))
  {
      url: 'https://api.segment.io/v1/batch',
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        ...
      },
      body: '...',
  }
  ```
  
  ### Emitter types

  The following table documents all the emitter types available in the Analytics Node.js library:

  | Emitter type      | Description                                                                 |
  |-------------------|-----------------------------------------------------------------------------|
  | `error`           | Emitted when there is an error after SDK initialization.                       |
  | `identify`        | Emitted when an Identify call is made.
  | `track`           | Emitted when a Track call is made.
  | `page`            | Emitted when a Page call is made.
  | `group`           | Emitted when a Group call is made.
  | `alias`           | Emitted when an Alias call is made.
  | `flush`            | Emitted after a batch is flushed.
  | `http_request`    | Emitted when an HTTP request is made.                                        |
  | `register`        | Emitted when a plugin is registered
  | `call_after_close`| Emitted when an event is received after the flush with `{ close: true }`.   |

  These emitters allow you to hook into various stages of the event lifecycle and handle them accordingly.


## Plugin architecture
The plugins you write can improve functionality, enrich data, and control the flow and delivery of events. From modifying event payloads to changing analytics functionality, plugins help to speed up the process of getting things done.


### Plugin categories
Segment has these five entry types of plugins:

| Type          | Details                                                                                                                                                                                                                                                                                                                                                                                                                   
| ------------- | ------------- |
| `before`      | Executes before event processing begins. These are plugins that run before any other plugins run. Thrown errors here can block the event pipeline. Source middleware added using `addSourceMiddleware` is treated as a `before` plugin. No events send to destinations until `.load()` method is resolved. |
| `enrichment`  | Executes as the first level of event processing. These plugins modify an event. Thrown errors here can block the event pipeline. No events send to destinations until `.load()` method is resolved. |
| `destination` | Executes as events begin to pass off to destinations. Segment.io is implemented as a destination plugin. Thrown errors here will _not_ block the event pipeline. |
| `after`       | Executes after all event processing completes. You can use this to perform cleanup operations. |
| `utility`     | Executes _only once_ during the bootstrap. Gives you access to the analytics instance using the plugin's `load()` method. This doesn't allow you to modify events. |

### Example plugin
Here's an example of a plugin that converts all track event names to lowercase before the event goes through the rest of the pipeline:

```js
export const lowercase: Plugin = {
  name: 'Lowercase events',
  type: 'enrichment',
  version: '1.0.0',

  isLoaded: () => true,
  load: () => Promise.resolve(),

  track: (ctx) => {
    ctx.updateEvent('event', ctx.event.event.toLowerCase())
    return ctx
  }
}
```

### Register a plugin
Registering plugins enable you to modify your analytics implementation to best fit your needs. You can register a plugin using this:

```js
// A promise will resolve once the plugins have been successfully loaded into Analytics.js
// Register multiple plugins at once by using the variable args interface in Analytics.js
await analytics.register(pluginA, pluginB, pluginC)
```

### Deregister a plugin
Deregister a plugin by using: 

```js
await analytics.deregister("pluginNameA", "pluginNameB") // takes strings
```

## Selecting destinations

The Alias, Group, Identify, Page, and Track calls can all be passed an object of `integrations` that lets you turn certain destinations on or off. By default all destinations are enabled.

Here's an example with the `integrations` object shown:

```javascript
analytics.track({
  event: 'Membership Upgraded',
  userId: '97234974',
  integrations: {
    'All': false,
    'Vero': true,
    'Google Analytics': false
  }
})
```

In this case, Segment specifies that they want this Track event to only go to Vero. `All: false` says that no destination should be enabled unless otherwise specified. `Vero: true` turns on Vero.

Destination flags are **case sensitive** and match [the destination's name in the docs](/docs/connections/destinations/) (for example, "AdLearn Open Platform", "awe.sm", or "MailChimp"). In some cases, there may be several names for a destination; if that happens you'll see a "Adding (destination name) to the Integrations Object" section in the destination's doc page with a list of valid names.

Keep in mind:

- Business Tier users can filter Track calls right from the Segment UI on your source schema page. We recommend using the UI if possible since it's a much simpler way of managing your filters and can be updated with no code changes on your side.

- If you are on a grandfathered plan, events sent server-side that are filtered through the Segment dashboard still count towards your API usage.

## Historical import

You can import historical data by adding the `timestamp` argument to any of your method calls. This can be helpful if you've just switched to Segment.

Historical imports can only be done into destinations that can accept historical timestamped data. Most analytics tools like Mixpanel, Amplitude, and Kissmetrics can handle that type of data just fine. One common destination that does not accept historical data is Google Analytics since their API cannot accept historical data.

**Note**: If you're tracking things that are happening right now, leave out the `timestamp` and Segment's servers will timestamp the requests for you.


## Batching

Segment's libraries are built to support high performance environments. That means it is safe to use Segment's Node library on a web server that's serving hundreds of requests per second.

Every method you call **doesn't** result in a HTTP request, but is queued in memory instead. Messages are then flushed in batch in the background, which allows for much faster operation.

By default, Segment's library will flush:

  - Every 15 messages (controlled by `settings.flushAt`).
  - If 10 seconds has passed since the last flush (controlled by `settings.flushInterval`)

There is a maximum of `500 KB` per batch request and `32 KB` per call.

If you don't want to batch messages, you can turn batching off by setting the `flushAt` setting to `1`, like so:

```javascript
const analytics = new Analytics({
  ...
  flushAt: 1
});
```

Batching means that your message might not get sent right away. Every method call takes an optional `callback`, which you can use to know when a particular message is flushed from the queue, like so:

```javascript
analytics.track({
    userId: '019mr8mf4r',
    event: 'Ultimate Played',
  },
  (err, ctx) => {
    ...
  }
)
```

## Multiple clients

Different parts of your application may require different types of batching, or even sending to multiple Segment sources. In that case, you can initialize multiple instances of `Analytics` with different settings:

```javascript
const marketingAnalytics = new Analytics({ writeKey: 'MARKETING_WRITE_KEY' });
const appAnalytics = new Analytics({ writeKey: 'APP_WRITE_KEY' });
```
## Override the default HTTP Client

Segment attempts to use the global `fetch` implementation if available in order to support several diverse environments.  Some special cases (for example, http proxy) may require a different implementation for http communication.  You can provide a customized wrapper in the Analytics configuration to support this.  Here are a few approaches:

Use a custom fetch-like implementation with proxy (Recommended)
```javascript
import { HTTPFetchFn } from '../lib/http-client'
import axios from 'axios'

const httpClient: HTTPFetchFn = async (url, { body, ...options }) =>
  axios({
    url,
    data: body,
    proxy: {
      protocol: 'http',
      host: 'proxy.example.com',
      port: 8886,
      auth: {
        username: 'user',
        password: 'pass',
      },
     },
    ...options,
  })

const analytics = new Analytics({
  writeKey: '<YOUR_WRITE_KEY>',
  httpClient,
})
```
Augment the default HTTP Client
```javascript
import { FetchHTTPClient, HTTPClientRequest  } from '@segment/analytics-node' 
 
class MyClient extends FetchHTTPClient {
  async makeRequest(options: HTTPClientRequest) {
    return super.makeRequest({
        ...options, 
        headers: { ...options.headers, foo: 'bar' }
      }})
  }
}

const analytics = new Analytics({ 
  writeKey: '<YOUR_WRITE_KEY>', 
  httpClient: new MyClient() 
})
```
Completely override the full HTTPClient (Advanced, you probably don't need to do this)
```javascript
import { HTTPClient, HTTPClientRequest } from '@segment/analytics-node'

class CustomClient implements HTTPClient {
  async makeRequest(options: HTTPClientRequest) {
    return someRequestLibrary(options.url, { 
      method: options.method,
      body: JSON.stringify(options.data) // serialize data
      headers: options.headers,
    })
  }
}
const analytics = new Analytics({ 
  writeKey: '<YOUR_WRITE_KEY>', 
  httpClient: new CustomClient() 
})
```
## Override context value
```javascript
analytics.track({
  anonymousId: '48d213bb-95c3-4f8d-af97-86b2b404dcfe',
  event: 'New Test',
  properties: {
    revenue: 39.95,
    shippingMethod: '2-day'
  },
  context: {
    traits: {
      "email": "test@test.com"
    }
  }
});
```


## OAuth 2.0

Enable [OAuth 2.0](/docs/connections/oauth/) in your Segment workspace to guarantee authorized communication between your server environment and Segment's Tracking API. To support the non-interactive server environment, the OAuth workflow used is a signed client assertion JWT.  

You will need a public and private key pair where:
- The public key is uploaded to the Segment dashboard. 
- The private key is kept in your server environment to be used by this SDK. 

Your server will verify its identity by signing a token request and will receive a token that is used to to authorize all communication with the Segment Tracking API.

You'll need to provide the OAuth Application ID and the public key's ID, both of which are provided in the Segment dashboard.  There are also options available to specify the authorization server, custom scope, maximum number of retries, or a custom HTTP client if your environment has special rules for separate Segment endpoints.

Be sure to implement handling for Analytics SDK errors. Good logging helps distinguish any configuration issues.

For more information, see the [Segment OAuth 2.0 documentation](/docs/connections/oauth/).

```ts
import { Analytics, OAuthSettings } from '@segment/analytics-node';
import { readFileSync } from 'fs'

const privateKey = readFileSync('private.pem', 'utf8')

const settings: OAuthSettings = {
  clientId: '<CLIENT_ID_FROM_DASHBOARD>',
  clientKey: privateKey,
  keyId: '<PUB_KEY_ID_FROM_DASHBOARD>',
}

const analytics = new Analytics({
  writeKey: '<MY_WRITE_KEY>',
  oauthSettings: settings,
})

analytics.on('error', (err) => { console.error(err) })

analytics.track({ userId: 'foo', event: 'bar' })
```
## Troubleshooting

{% include content/troubleshooting-intro.md %}
{% include content/troubleshooting-server-debugger.md %}
{% include content/server-side-troubleshooting.md %}
